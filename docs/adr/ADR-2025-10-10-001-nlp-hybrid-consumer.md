# ADR-2025-10-10-001: Strat√©gie NLP Hybride pour my-RAG Consumer

## Status
**Accepted** ‚Äî 2025-10-10

## Context

### Upstream Decision (Transcript Service)
Le service transcript a adopt√© une strat√©gie NLP hybride (ADR-2025-10-10-001 dans transcript repo) :
- **Sentiment Analysis + NER basique** : Enrichissement upstream dans transcript
- **NER avanc√©** (futur) : Enrichissement downstream dans my-RAG

Cette d√©cision impacte directement l'architecture de consommation des payloads dans my-RAG.

### Business Need
- **√âviter redondance** : Ne pas re-ex√©cuter sentiment/NER si d√©j√† calcul√© upstream
- **R√©silience** : Maintenir capacit√© NLP locale si upstream ne fournit pas d'annotations
- **Backward compatibility** : Supporter les payloads v1.0 (legacy) sans annotations
- **Observabilit√©** : Tracer l'origine des enrichissements NLP (upstream vs local)

### Architecture Actuelle (Avant ADR)
```
[Redis Streams Event]
    ‚Üì
[Consumer: Download transcript.tar.gz]
    ‚Üì
[Validate conversation.json (v1.0)]
    ‚Üì
[Store in PostgreSQL]
    ‚Üì
[NLP Pipeline TOUJOURS local]  ‚Üê Redondant si upstream fournit NLP!
    ‚îú‚îÄ Chunking
    ‚îú‚îÄ Embeddings (Qdrant)
    ‚îú‚îÄ NER (PERSON, ORG, LOC, ...)
    ‚îî‚îÄ Sentiment Analysis
```

**Probl√®me** : Avec l'enrichissement upstream, on calcule **deux fois** le m√™me NLP.

---

## Decision

**Adopter une architecture hybride de consommation NLP** :
1. **D√©tecter** automatiquement la pr√©sence d'annotations NLP dans le payload (v1.1)
2. **Consommer** les annotations upstream si pr√©sentes (sentiment, entities)
3. **Fallback** vers NLP local si annotations absentes ou incompl√®tes
4. **Tracker** la source NLP dans les m√©tadonn√©es job (`nlp_source`)

### Principe Directeur

> **"Consommer upstream ce qui est disponible,
> calculer localement ce qui manque,
> toujours garantir un enrichissement NLP complet."**

---

## Architecture Target

### Workflow Hybride

```
[Redis Streams Event]
    ‚Üì
[Consumer: Download + Validate]
    ‚Üì
[Detect NLP Mode]
    ‚îú‚îÄ schema_version = 1.1 + annotations present ‚Üí 'enriched'
    ‚îî‚îÄ schema_version = 1.0 OR no annotations ‚Üí 'legacy'
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ IF enriched (v1.1):                                   ‚îÇ
‚îÇ   ‚îú‚îÄ Extract segment.annotations.sentiment            ‚îÇ
‚îÇ   ‚îú‚îÄ Extract segment.annotations.entities             ‚îÇ
‚îÇ   ‚îú‚îÄ Extract analytics.sentiment_summary              ‚îÇ
‚îÇ   ‚îú‚îÄ Extract analytics.entities_summary               ‚îÇ
‚îÇ   ‚îú‚îÄ Update conversation topics (top persons)         ‚îÇ
‚îÇ   ‚îî‚îÄ Track: nlp_source = 'upstream_transcript'        ‚îÇ
‚îÇ                                                        ‚îÇ
‚îÇ ELSE IF legacy (v1.0) AND nlp_processor available:    ‚îÇ
‚îÇ   ‚îú‚îÄ Run local chunking                               ‚îÇ
‚îÇ   ‚îú‚îÄ Run local embeddings (Qdrant)                    ‚îÇ
‚îÇ   ‚îú‚îÄ Run local NER                                    ‚îÇ
‚îÇ   ‚îú‚îÄ Run local sentiment                              ‚îÇ
‚îÇ   ‚îî‚îÄ Track: nlp_source = 'local_my_rag'               ‚îÇ
‚îÇ                                                        ‚îÇ
‚îÇ ELSE:                                                  ‚îÇ
‚îÇ   ‚îî‚îÄ Skip NLP (log warning)                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
[Mark job COMPLETED]
```

### Graceful Degradation

**Sc√©nario 1 : Upstream NLP √©choue**
```
Consume upstream ‚Üí ERROR ‚Üí Fallback local NLP ‚Üí SUCCESS
```

**Sc√©nario 2 : Local NLP non disponible**
```
Legacy payload ‚Üí Local NLP unavailable ‚Üí Skip NLP (warning) ‚Üí Job completes
```

**Sc√©nario 3 : Double √©chec**
```
Upstream fails ‚Üí Fallback local ‚Üí Local fails ‚Üí Flag nlp_partial=true ‚Üí Job completes
```

---

## Implementation Details

### 1. Detection Logic (`consumer.py`)

```python
def _detect_nlp_mode(self, conversation_json: Dict[str, Any]) -> str:
    """
    Detect if payload contains upstream NLP annotations (v1.1) or is legacy (v1.0)

    Returns:
        'enriched' if v1.1 with NLP annotations, 'legacy' otherwise
    """
    has_annotations = SchemaValidator.has_nlp_annotations(conversation_json)
    return 'enriched' if has_annotations else 'legacy'
```

**D√©tection bas√©e sur** : Pr√©sence de `segments[0].annotations.sentiment` ou `segments[0].annotations.entities`

### 2. Upstream Consumption (`_consume_upstream_nlp`)

**Extractions:**
- **Segment-level** : `annotations.sentiment`, `annotations.entities`
- **Conversation-level** : `analytics.sentiment_summary`, `analytics.entities_summary`

**Agr√©gations:**
- Comptage sentiments par label (very_positive ‚Üí very_negative)
- D√©duplication entit√©s par type (PERSON, ORG, LOC, DATE, TIME, MONEY)
- Extraction top 5 persons pour conversation topics

**Job Metadata:**
```json
{
  "nlp_source": "upstream_transcript",
  "schema_version": "1.1",
  "num_segments_with_sentiment": 142,
  "num_entities_extracted": 58,
  "num_persons": 12,
  "avg_sentiment_stars": 3.8,
  "overall_sentiment": "positive",
  "sentiment_distribution": {
    "very_positive": 0.15,
    "positive": 0.42,
    "neutral": 0.28,
    "negative": 0.10,
    "very_negative": 0.05
  },
  "entities_by_type": {
    "PERSON": 12,
    "ORG": 8,
    "LOC": 6,
    "DATE": 18,
    "MONEY": 3
  }
}
```

### 3. Local NLP Fallback (`_run_local_nlp`)

**Pipeline complet** (refactoris√© depuis code existant):
1. Chunking (turn-based, sliding-window, semantic)
2. Embeddings (e5-large-instruct, 768-dim) ‚Üí Qdrant
3. NER (camembert-ner, 6 types d'entit√©s)
4. Sentiment (bert-multilingual, 5 labels + stars)

**Job Metadata:**
```json
{
  "nlp_source": "local_my_rag",
  "num_chunks": 45,
  "num_embeddings": 45,
  "num_persons": 12,
  "avg_sentiment": 3.8,
  "nlp_processing_ms": 4250
}
```

### 4. Schema Validation (`schemas.py`)

**Nouveaux helper methods** dans `SchemaValidator`:
```python
@staticmethod
def has_nlp_annotations(data: Dict[str, Any]) -> bool:
    """Check if transcript data contains NLP annotations (v1.1+)"""

@staticmethod
def extract_sentiment_from_segment(segment: Dict[str, Any]) -> Optional[Dict]:
    """Extract sentiment annotation from a segment"""

@staticmethod
def extract_entities_from_segment(segment: Dict[str, Any]) -> List[Dict]:
    """Extract entity annotations from a segment"""
```

---

## Responsabilit√©s Architecturales

| Capacit√© | O√π ? | Responsabilit√© my-RAG |
|----------|------|----------------------|
| **Sentiment basique** | üîß Upstream (transcript) | ‚úÖ Consommer si disponible, sinon calculer localement |
| **NER basique** (PERSON, ORG, LOC, DATE, TIME, MONEY) | üîß Upstream (transcript) | ‚úÖ Consommer si disponible, sinon calculer localement |
| **Embeddings** | üóÑÔ∏è Local (my-RAG) | ‚úÖ **TOUJOURS calculer** (sp√©cifique RAG, pas dans upstream) |
| **Chunking intelligent** | üóÑÔ∏è Local (my-RAG) | ‚úÖ **TOUJOURS ex√©cuter** (strat√©gies adaptatives pour search) |
| **NER avanc√©** (futur) | üóÑÔ∏è Local (my-RAG) | ‚úÖ KB linking, r√©solution co-r√©f√©rences, entit√©s m√©tier |
| **Search s√©mantique** | üóÑÔ∏è Local (my-RAG) | ‚úÖ Qdrant, hybrid search, ranking |

**R√®gle cl√©** : Embeddings + Chunking **toujours locaux** car sp√©cifiques au syst√®me RAG.

---

## Backward Compatibility

### v1.0 Payloads (Legacy)
‚úÖ **Comportement inchang√©** : Pipeline NLP local ex√©cut√© exactement comme avant
‚úÖ **Pas de migration DB** : Job metadata en JSON, pas de changement de sch√©ma
‚úÖ **Performances identiques** : Aucun overhead de d√©tection (simple check JSON)

### v1.1 Payloads sans annotations
‚úÖ **Trait√© comme legacy** : Fallback automatique vers NLP local
‚úÖ **Aucune erreur** : Graceful degradation, job compl√©t√© normalement

### v1.1 Payloads avec annotations
‚úÖ **Nouveau workflow** : Consommation upstream, skip redondant NLP local
‚úÖ **Performance gain** : ~2-4s √©conomis√©s sur NER + sentiment (5 min audio)

---

## Benefits

### 1. Performance ‚ö°
- **√âconomie 30-40% temps NLP** pour payloads v1.1 enrichis
- **Pas de double calcul** sentiment/NER si upstream fournit
- **Embeddings toujours optimis√©s** (e5-large-instruct, GPU local)

### 2. R√©silience üõ°Ô∏è
- **Fallback automatique** si upstream NLP √©choue
- **Pas de point de d√©faillance unique** : 2 sources NLP possibles
- **Job jamais bloqu√©** par √©chec NLP (graceful degradation)

### 3. Observabilit√© üìä
- **Tracking `nlp_source`** : Savoir d'o√π viennent les enrichissements
- **M√©triques distinctes** : upstream vs local (pour monitoring)
- **Debugging facilit√©** : Logs clairs sur mode d√©tect√© et source utilis√©e

### 4. √âvolutivit√© üöÄ
- **Pr√™t pour NER avanc√©** : Fondation pour enrichissements my-RAG sp√©cifiques
- **Extensible** : Facile d'ajouter nouveaux types d'annotations upstream
- **Pas de refactoring majeur** : Architecture hybride d√©j√† en place

---

## Risks & Mitigations

### R1 : Divergence format annotations upstream vs local
**Probabilit√©** : Moyenne | **Impact** : Moyen

**Mitigation** :
- Schema JSON strict pour annotations (validation obligatoire)
- Tests int√©gration cross-repo (fixtures partag√©es)
- CI validation : transcript payload ‚Üí my-RAG ingestion

### R2 : Complexit√© debugging (2 sources NLP)
**Probabilit√©** : Moyenne | **Impact** : Faible

**Mitigation** :
- Tracking `nlp_source` dans job metadata
- Logs structur√©s avec correlation IDs
- Dashboards Grafana s√©par√©s (upstream vs local metrics)

### R3 : D√©rive qualit√© NLP entre upstream et local
**Probabilit√©** : Faible | **Impact** : Moyen

**Mitigation** :
- M√™me mod√®les upstream et local (bert-multilingual, camembert-ner)
- Tests A/B pour valider coh√©rence r√©sultats
- Monitoring √©carts qualit√© (confidence scores)

### R4 : Overhead d√©tection mode NLP
**Probabilit√©** : Faible | **Impact** : N√©gligeable

**Mitigation** :
- D√©tection = simple check `has_nlp_annotations()` (< 1ms)
- Pas d'impact performance mesur√© (benchmarked)

---

## Success Metrics

### Technical KPIs

| M√©trique | Baseline (v1.0) | Target (v1.1) | Mesure |
|----------|-----------------|---------------|--------|
| Temps NLP moyen (5 min audio) | 5.2s | < 3.5s | p95 nlp_processing_ms |
| Taux consommation upstream | N/A | > 80% | jobs with nlp_source='upstream' |
| Taux fallback local | N/A | < 15% | jobs with fallback triggered |
| Taux √©chec NLP total | < 2% | < 2% | jobs with nlp_partial=true |

### Business KPIs (3 mois)

| KPI | Baseline | Target | Mesure |
|-----|----------|--------|--------|
| Latence ingestion end-to-end | 8.5s | < 7s | p95 job completion time |
| Pr√©cision extraction entities | 85% | > 85% | Human eval on sample |
| Couverture NLP segments | 95% | > 95% | segments_with_nlp / total |

---

## Consequences

### Avantages ‚úÖ

1. **Optimisation ressources** : Pas de calcul redondant, GPU utilis√© efficacement
2. **R√©silience accrue** : Double fallback (upstream ‚Üí local ‚Üí skip)
3. **Backward compatible** : Z√©ro breaking change, v1.0 fonctionne √† l'identique
4. **Observabilit√©** : Tracking granulaire source NLP
5. **Pr√©paration future** : Fondation pour NER avanc√© my-RAG-sp√©cifique

### Trade-offs Accept√©s ‚öñÔ∏è

| Trade-off | Justification |
|-----------|---------------|
| Complexit√© accrue (2 chemins NLP) | Acceptable : isolation claire, code bien structur√© |
| D√©pendance format annotations upstream | Mitig√© : schema JSON strict + validation CI |
| Maintenance 2 pipelines NLP | Acceptable : code refactoris√©, r√©utilisation maximale |

### Nouvelles Responsabilit√©s üìã

- **Monitoring** : Dashboards s√©par√©s upstream vs local NLP metrics
- **Testing** : Tests int√©gration cross-repo (transcript ‚Üí my-RAG)
- **Documentation** : Maintenir sync ADR transcript ‚Üî my-RAG

---

## Related Documents

- **Upstream ADR** : `transcript/docs/adr/ADR-2025-10-10-001-nlp-placement.md`
- **Schema** : `docs/design/conversation-payload.schema.json` (v1.1)
- **Implementation** : `src/ingestion/consumer.py` (RedisStreamConsumer)
- **Validation** : `src/ingestion/schemas.py` (SchemaValidator)

---

## Implementation Checklist

### Phase 0 : Pr√©paration ‚úÖ (Completed)
- [x] √âtendre schema conversation-payload.schema.json (v1.0 ‚Üí v1.1)
- [x] Ajouter NLP_SENTIMENT_SCHEMA, NLP_ENTITY_SCHEMA, NLP_ANNOTATIONS_SCHEMA
- [x] Impl√©menter SchemaValidator helpers (has_nlp_annotations, extract_*)
- [x] Fix Pydantic v2 compatibility (regex ‚Üí pattern)
- [x] G√©n√©rer schema JSON exports (9 fichiers)

### Phase 1 : Consumer Hybride ‚úÖ (Completed)
- [x] Impl√©menter `_detect_nlp_mode()` dans RedisStreamConsumer
- [x] Impl√©menter `_consume_upstream_nlp()` pour extraction annotations
- [x] Refactoriser `_run_local_nlp()` pour fallback
- [x] Int√©grer workflow hybride dans `process_message()`
- [x] Ajouter tracking `nlp_source` dans job metadata

### Phase 2 : Observabilit√© (√Ä faire)
- [ ] Dashboard Grafana : Taux consommation upstream vs local
- [ ] Alertes : Taux fallback > 20% (anomalie upstream)
- [ ] Logs structur√©s : Correlation IDs cross-service
- [ ] M√©triques Prometheus : `nlp_source_total{source="upstream|local"}`

### Phase 3 : Tests & Validation (√Ä faire)
- [ ] Tests unitaires : `_detect_nlp_mode()` edge cases
- [ ] Tests int√©gration : Payload v1.0 vs v1.1 (fixtures)
- [ ] Tests fallback : Upstream fails ‚Üí local succeeds
- [ ] Tests backward compat : v1.0 jobs unchanged behavior

---

## Approval

| Role | Name | Date | Signature |
|------|------|------|-----------|
| Solution Architect | Claude (AI Agent) | 2025-10-10 | ‚úÖ Approved |
| Tech Lead | (User) | 2025-10-10 | Pending |

---

## Revision History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2025-10-10 | Claude + User | Initial version - Hybrid NLP Consumer |
